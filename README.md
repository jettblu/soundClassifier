Data Collection:
A Zoom H1n microphone was used to capture stereo audio at 48000 Hz with a built-in low-cut filter removing low frequencies. Blender and microwave data were collected over the course of several days while using the appliances as normal. Music, alarm, and vacuum data were obtained by recording audio files obtained on the internet from a variety of angles and distances. The data was then separated into folders containing 20 samples each, preprocessed via methods described below, and saved as a .npy file for quick access during model development. This code can be found in the file labeled ‘file construction.py’.
Preprocessing occurred during both .npy file construction and feature selection using the Librosa module. During file construction, raw sound data was loaded via the librosa.load method which collapsed the two audio channels into one, converted the sampling rate to 22050 Hz, and normalized audio values to between -1 and 1. These steps allowed for a faster model and accounted for deviations in volume due to distance. 

Feature Engineering:
Due to a lack of domain specific knowledge with respect to audio, I reviewed a series of videos, projects, and papers to gain a better understanding of what features typically provide the best performance in supervised learning models. I found that many existing approaches have found success using Mel Frequency Cepstral Co-efficients (MFCC) and so I included the first 13 coefficients as features after experimenting with varying quantities of coefficients. In addition, I researched the feature methods included within the librosa module and settled upon eight unique features—such as zero crossing rate and spectral centroid— that have been proven to work in similar audio classification tasks. To account for the differing lengths of each sample I divided each feature by sample length as necessary; this prevented time from becoming a confounding variable. Features were preprocessed at run time using a min/ max scaler which provided for a bigger performance increase (9%) than other scalers available in the scikit library.
After finding little initial success with random forests, I switched to K Nearest Neighbors and SVM algorithms which were better suited to the small training population. Principle component analysis (PCA)—used for its ability to reduce overfitting and feature dimensionality— led to a marginal increase in SVM performance, while boosting KNN performance by 4%. MFCC provided around a 70% accuracy score when used in conjunction with PCA. The addition of the features mentioned above then led to a roughly 5% increase in model performance, providing a final accuracy measure of around 78% when combined with parameter optimization. 



Graphs and Design Decisions:
The features fed into each model were obtained with a window size of 2048 and a sample rate of 512 within each frame. I tried bigger window sizes, however, the drastic increase in computation was not worth the negligible increase in accuracy. 
   
The KNN classifier has the fewest and most accurate boundaries, which is reflected in the algorithm’s performance on the data set. The SVM algorithm achieves a similar degree of accuracy, however, I decided to implement KNN as it is more understandable/ generalizable with this specific feature set. After adopting KNN, I set about fine tuning parameters and settled upon 2 neighbors as the optimal amount for ‘kneighbors’ queries. The final classification code can be found under ‘sound classifier.py’.

